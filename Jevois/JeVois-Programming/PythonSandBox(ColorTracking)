import libjevois as jevois
import cv2
import numpy as np 

# By default, we get the next video frame from the camera as an OpenCV RGB (color) image named 'inimg'.
# We then apply some image processing to it to create an output RGB image named 'outimg'.
# We finally add some text drawings to outimg and send it to host over USB.
#
# @author Laurent Itti edited by Preston Stevens and Aaron Santa Cruz
# 
# @videomapping YUYV 352 288 30.0 YUYV 352 288 30.0 JeVois PythonSandbox

class PythonSandbox:
	# ###################################################################################################
	## Constructor
	def __init__(self):
		# Instantiate a JeVois Timer to measure our processing framerate:
		self.timer = jevois.Timer("sandbox", 100, jevois.LOG_INFO)
		
	# ###################################################################################################
	## Process function with USB output
	def process(self, inframe, outframe):
		# Get the next camera image (may block until it is captured) and here convert it to OpenCV BGR by default. If
		# you need a grayscale image instead, just use getCvGRAY() instead of getCvBGR(). Also supported are getCvRGB()
		# and getCvRGBA():
		inimg = inframe.getCvBGR()
		
		# Start measuring image processing time (NOTE: does not account for input conversion time):
		self.timer.start()

		# Detect edges using the Laplacian algorithm from OpenCV:
		#
		# Replace the line below by your own code! See for example

		# - http://docs.opencv.org/trunk/d9/d61/tutorial_py_morphological_ops.html
		# - http://docs.opencv.org/trunk/d5/d0f/tutorial_py_gradients.html
		# - http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html
		#
		# and so on. When they do "img = cv2.imread('name.jpg', 0)" in these tutorials, the last 0 means they want a
		# gray image, so you should use getCvGRAY() above in these cases. When they do not specify a final 0 in imread()
		# then usually they assume color and you should use getCvBGR() here.
		# convert bgr to hsv
		hsv = cv2.cvtColor(inimg, cv2.COLOR_RGB2HSV)

		# define range of yellow color in HSV
		lower_yellow = np.array([40,100,170])
		upper_yellow = np.array([170,255,255])

		# Threshold the HSV image to get only yellow colors
		mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

		# Bitwise-And mask and original image
		outimg = cv2.bitwise_and(inimg, inimg, mask= mask)	
				
		# Write a title:
		cv2.putText(outimg, "JeVois Python Sandbox", (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255),
					1, cv2.LINE_AA)
		
		# Write frames/s info from our timer into the edge map (NOTE: does not account for output conversion time):
		fps = self.timer.stop()
		height, width, channels = outimg.shape # if outimg is grayscale, change to: height, width = outimg.shape
		cv2.putText(outimg, fps, (3, height - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)
		
		# assigning blur variable to blur live output
		
		blur = cv2.GaussianBlur(outimg,(5,5),0)
		
		# Convert our BGR output image to video output format and send to host over USB. If your output image is not
		# BGR, you can use sendCvGRAY(), sendCvRGB(), or sendCvRGBA() as appropriate:
		outframe.sendCvBGR(blur)
